{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "134a5622-31fd-4f46-881a-c370ef84a3b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Access Azure Data Lake useing access keys\n",
    "1. set the spark cofig SAS Token\n",
    "2. list files from demo container\n",
    "3. read data from circuits.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75139148-d831-418c-83ee-8126f1fb50fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Access format\n",
    "abfss://container_name@storage_account_name.dfs.core.widows.net/folder_path/file_name\n",
    "\n",
    "##Access Using SAS tokens\n",
    "To access using key, have to set spark conf. \n",
    "\n",
    "spark.conf.set(\"fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net\", \"SAS\")\n",
    "\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.<storage-account>.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.<storage-account>.dfs.core.windows.net\",<sas-token-key>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a10622ad-6d99-45cd-916d-143c6b774a11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">\n",
       "Provides utilities for leveraging secrets within notebooks.\n",
       "Databricks documentation for more info.\n",
       "    <h3></h3><b>get(scope: String, key: String): String</b> -> Gets the string representation of a secret value with scope and key<br /><b>getBytes(scope: String, key: String): byte[]</b> -> Gets the bytes representation of a secret value with scope and key<br /><b>list(scope: String): Seq</b> -> Lists secret metadata for secrets within a scope<br /><b>listScopes: Seq</b> -> Lists secret scopes<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\">\nProvides utilities for leveraging secrets within notebooks.\nDatabricks documentation for more info.\n    <h3></h3><b>get(scope: String, key: String): String</b> -> Gets the string representation of a secret value with scope and key<br /><b>getBytes(scope: String, key: String): byte[]</b> -> Gets the bytes representation of a secret value with scope and key<br /><b>list(scope: String): Seq</b> -> Lists secret metadata for secrets within a scope<br /><b>listScopes: Seq</b> -> Lists secret scopes<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.secrets.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cddb08d7-8679-4e8f-be01-f1e3c1700664",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sas_token = dbutils.secrets.get(scope='formula1-scope', key='formula-1-demo-sas-token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6dfccef-0dc6-4a27-be5d-b8a7c32fda3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.auth.type.dlformulaone2024.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.dlformulaone2024.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.dlformulaone2024.dfs.core.windows.net\", sas_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fb8b522-aa36-4bdd-9b82-01ca0dbf70df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>abfss://demo@dlformulaone2024.dfs.core.windows.net/circuits.csv</td><td>circuits.csv</td><td>10044</td><td>1705788401000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "abfss://demo@dlformulaone2024.dfs.core.windows.net/circuits.csv",
         "circuits.csv",
         10044,
         1705788401000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"abfss://demo@dlformulaone2024.dfs.core.windows.net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3860e38-cfbe-4a8d-be59-55fd6b5c0fc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"abfss://demo@dlformulaone2024.dfs.core.windows.net/circuits.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c7c16c-ea16-48d7-8995-14ae81baad76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n|     country|count(1)|\n+------------+--------+\n|      Russia|       1|\n|      Sweden|       1|\n|    Malaysia|       1|\n|   Singapore|       1|\n|      Turkey|       1|\n|     Germany|       3|\n|      France|       7|\n|   Argentina|       1|\n|     Belgium|       3|\n|       China|       1|\n|       India|       1|\n|       Italy|       4|\n|       Spain|       6|\n|      Monaco|       1|\n|     Morocco|       1|\n|         USA|      11|\n|      Mexico|       1|\n|  Azerbaijan|       1|\n|          UK|       4|\n|Saudi Arabia|       1|\n+------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"tableA\")\n",
    "spark.sql(\"SELECT country, count(1) from tableA  GROUP BY country\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.access_adls_using_sas_token",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
